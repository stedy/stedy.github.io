
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>Zach Stednick</title>
	<meta name="author" content="Zach Stednick">

	
	<meta name="description" content="I wanted to revist my previous
post
continuing to look at using linear
regression for determining the best
episodes of a TV show to watch. I started &hellip;">
	
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="Zach Stednick" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script async="true" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">Zach Stednick</a></h1>
<nav id="main-nav"><ul class="main">
	<li><a href="/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul class="main">
	<li><a href="/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="https://www.google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:stedy.github.io">
			</form>
		</div>
	</div>
</nav>
<nav id="sub-nav" class="alignright">
	<div class="social">
		
		
		
		<a class="twitter" href="http://twitter.com/zachstednick" title="Twitter">Twitter</a>
		
		
		<a class="github" href="https://github.com/stedy" title="GitHub">GitHub</a>
		
    
		
		
		
		
		
		<a class="rss" href="/atom.xml" title="RSS">RSS</a>
		
    
	</div>
	<form class="search" action="https://www.google.com/search" method="get">
		<input class="alignright" type="text" name="q" results="0">
		<input type="hidden" name="q" value="site:stedy.github.io">
	</form>
</nav>

</header>
	
		
	
	<div id="content" class="inner">


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/09/30/further-exploration-of-imdb-tv-show-rating-data/">
		
			Further Exploration of IMDb TV Show Rating Data</a>
	</h2>
	<div class="entry-content">
		<p>I wanted to revist my previous
<a href="http://zachstednick.name/blog/2017/08/09/smarter-binge-watching-with-linear-regression/">post</a>
continuing to look at using linear
regression for determining the best
episodes of a TV show to watch. I started to think about how to look at
this data for multiple TV shows. Performing a linear regression on show
rating by episode number within a season quickly allows us to determine
the maximum and minimum residual for all the show episodes. I took this
a step further and
calculated which episode of the show it was. For example, here are all
the episodes with residual value for that particular show <a href="http://www.imdb.com/title/tt4635276/">Master of
None</a>:</p>

<table>
<thead>
<tr>
<th>Season</th>
<th style="text-align:center;">Episode</th>
<th style="text-align:center;">Name</th>
<th style="text-align:center;">Residual</th>
<th style="text-align:center;">count</th>
<th style="text-align:right;">appearance</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td style="text-align:center;">1</td>
<td style="text-align:center;">               Plan B</td>
<td style="text-align:center;">-0.28</td>
<td style="text-align:center;">1</td>
<td style="text-align:right;">0.05</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">2</td>
<td style="text-align:center;">              Parents</td>
<td style="text-align:center;">0.21</td>
<td style="text-align:center;">2</td>
<td style="text-align:right;">0.1</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">3</td>
<td style="text-align:center;">           Hot Ticket</td>
<td style="text-align:center;">0.01</td>
<td style="text-align:center;">3</td>
<td style="text-align:right;">0.15</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">4</td>
<td style="text-align:center;">        Indians on TV</td>
<td style="text-align:center;">0.21</td>
<td style="text-align:center;">4</td>
<td style="text-align:right;">0.2</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">5</td>
<td style="text-align:center;">        The Other Man</td>
<td style="text-align:center;">-0.09</td>
<td style="text-align:center;">5</td>
<td style="text-align:right;">0.25</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">6</td>
<td style="text-align:center;">            Nashville</td>
<td style="text-align:center;">0.31</td>
<td style="text-align:center;">6</td>
<td style="text-align:right;">0.3</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">7</td>
<td style="text-align:center;"> Ladies and Gentlemen</td>
<td style="text-align:center;">-0.39</td>
<td style="text-align:center;">7</td>
<td style="text-align:right;">0.35</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">8</td>
<td style="text-align:center;">           Old People</td>
<td style="text-align:center;">-0.09</td>
<td style="text-align:center;">8</td>
<td style="text-align:right;">0.4</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">9</td>
<td style="text-align:center;">             Mornings</td>
<td style="text-align:center;">0.11</td>
<td style="text-align:center;">9</td>
<td style="text-align:right;">0.45</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">10</td>
<td style="text-align:center;">               Finale</td>
<td style="text-align:center;">0.01</td>
<td style="text-align:center;">10</td>
<td style="text-align:right;">0.5</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">1</td>
<td style="text-align:center;">            The Thief</td>
<td style="text-align:center;">0.44</td>
<td style="text-align:center;">11</td>
<td style="text-align:right;">0.55</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">2</td>
<td style="text-align:center;">             Le Nozze</td>
<td style="text-align:center;">-0.36</td>
<td style="text-align:center;">12</td>
<td style="text-align:right;">0.6</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">3</td>
<td style="text-align:center;">             Religion</td>
<td style="text-align:center;">-0.27</td>
<td style="text-align:center;">13</td>
<td style="text-align:right;">0.65</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">4</td>
<td style="text-align:center;">           First Date</td>
<td style="text-align:center;">0.13</td>
<td style="text-align:center;">14</td>
<td style="text-align:right;">0.7</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">5</td>
<td style="text-align:center;">     The Dinner Party</td>
<td style="text-align:center;">0.02</td>
<td style="text-align:center;">15</td>
<td style="text-align:right;">0.75</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">6</td>
<td style="text-align:center;"> New York, I Love You</td>
<td style="text-align:center;">0.42</td>
<td style="text-align:center;">16</td>
<td style="text-align:right;">0.8</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">7</td>
<td style="text-align:center;">              Door #3</td>
<td style="text-align:center;">-0.89</td>
<td style="text-align:center;">17</td>
<td style="text-align:right;">0.85</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">8</td>
<td style="text-align:center;">         Thanksgiving</td>
<td style="text-align:center;">0.31</td>
<td style="text-align:center;">18</td>
<td style="text-align:right;">0.9</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">9</td>
<td style="text-align:center;">         Amarsi Un Po</td>
<td style="text-align:center;">0.30</td>
<td style="text-align:center;">19</td>
<td style="text-align:right;">0.95</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">10</td>
<td style="text-align:center;">          Buona Notte</td>
<td style="text-align:center;">-0.10</td>
<td style="text-align:center;">20</td>
<td style="text-align:right;">1</td>
</tr>
</tbody>
</table>


<p>We can see that the episode with the highest residual is S2E1 &ldquo;The
Thief&rdquo; and the episode with the lowest residual is S2E7 &ldquo;Door #3&rdquo;. For
every TV show I took all the episodes and calculated their order as a percent of
the total number of episodes - for example the pilot episode would be 0.0 and the
series
finale would be 1.0 to generate an index. I then took the
maximum and minimum residual values for each show and plotted them
against that episode. For example here is a plot of just Master of None:</p>

<iframe src="http://zachstednick.com/mon_min_max.html" marginwidth="0" marginheight="0" style="height:500px; width:800px;" scrolling="no"></iframe>


<p>To obtain data on as many shows as I could I used this <a href="http://www.imdb.com/search/title?at=0&amp;num_votes=5000,&amp;sort=user_rating,de">IMDb
list</a>
of shows with over 5000 votes and selected the first 1200 shows as a
dataset. I then reused the <a href="http://www.omdbapi.com/">OMDb API</a> as I did before. I then calculated the same values as I did for Master of None
above and plotted them in a similar manner (use the mouseover for more
information on each point):</p>

<iframe src="http://zachstednick.com/imdb_min_max.html" marginwidth="0" marginheight="0" style="height:500px; width:800px;" scrolling="no"></iframe>


<p>Two things immediately jump out at me:</p>

<ol>
<li><p>The density of points right around the zero line shows that linear
regression is a pretty good metric to use for this type of analysis and
that most people rate the show generally in line with the overall trend
for that particular season.</p></li>
<li><p>There seems to be a tendancy for people to really love or really hate
the series finale of TV shows and this shows up by the sheer number of
points at 1. Possibly this is people expressing their overall view of
the show as a whole or maybe people really were really happy or unhappy
with the series finale.</p></li>
</ol>


<p>I put some of the main code I used in a <a href="https://github.com/stedy/blog-supplemental">GitHub
repository</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-09-30T13:57:18-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/r-python-imdb/'>r,python,imdb</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/08/09/smarter-binge-watching-with-linear-regression/">
		
			Smarter Binge Watching With Linear Regression</a>
	</h2>
	<div class="entry-content">
		<p>I am not much of a binge watcher but I do enjoy quality TV shows which
is why I think <a href="http://graphtv.kevinformatics.com/">GraphTV</a> is so
great. GraphTV plots the IMDb user ratings for every episode
and then performs a
<a href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> of
the episode rating by the episode number to create a trend line which
helps you see if the show gets better or worse over the course of the
season.</p>

<p>This is nice but it can get difficult to use GraphTV for shows like
<a href="http://graphtv.kevinformatics.com/tt0088526">Golden Girls</a> and
downright impossible for shows like <a href="http://graphtv.kevinformatics.com/tt0096697">The
Simpsons</a>.</p>

<p>To solve this I created a GitHub repo
<a href="https://github.com/stedy/binge-trendy">binge-trendy</a>. Because the trend
line is fit to the IMDb user rating data, we are
interested in which episodes do IMDb users think are better than the
regression model predicts which translates to any deviation from the
trend line. Since I am only interested in episodes that are
rated higher than the regression model would have predicted,
I only look at episodes with a positive residual.</p>

<p>For example, Golden Girls season 4</p>

<table>
<thead>
<tr>
<th>   Season</th>
<th style="text-align:center;"> Episode </th>
<th style="text-align:right;">                                Name</th>
</tr>
</thead>
<tbody>
<tr>
<td>       4 </td>
<td style="text-align:center;">     1 </td>
<td style="text-align:right;">               Yes, We Have No Havanas</td>
</tr>
<tr>
<td>       4 </td>
<td style="text-align:center;">     2 </td>
<td style="text-align:right;">The Days and Nights of Sophia Petrillo</td>
</tr>
<tr>
<td>       4 </td>
<td style="text-align:center;">     6 </td>
<td style="text-align:right;">              Sophia&rsquo;s Wedding: Part 1</td>
</tr>
<tr>
<td>       4 </td>
<td style="text-align:center;">     9 </td>
<td style="text-align:right;">                       Scared Straight</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   11  </td>
<td style="text-align:right;">                          The Auction</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   14  </td>
<td style="text-align:right;">                       Love Me Tender</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   15  </td>
<td style="text-align:right;">                      Valentine&rsquo;s Day</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   19  </td>
<td style="text-align:right;">              Till Death Do We Volley</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   20  </td>
<td style="text-align:right;">                         High Anxiety</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   22  </td>
<td style="text-align:right;">                      Sophia&rsquo;s Choice</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   23  </td>
<td style="text-align:right;">                      Rites of Spring</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   24  </td>
<td style="text-align:right;">                     Foreign Exchange</td>
</tr>
</tbody>
</table>


<p>I realize the code is not great,
<a href="https://pypi.python.org/pypi/pylint">pylint</a> currently gives it a 6.05 but if there is
one thing I have learned in software:</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en"
dir="ltr">The only way to write good code is to write tons of shitty
code first. Feeling shame about bad code stops you from getting to good
code</p>&mdash; Hadley Wickham (@hadleywickham) <a
href="https://twitter.com/hadleywickham/status/589068687669243905">April
17, 2015</a></blockquote>


<script async src="//platform.twitter.com/widgets.js"
charset="utf-8"></script>


		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-08-09T21:32:39-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/python-imdb/'>python,imdb</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/07/05/standing-up-for-net-neutrality/">
		
			Standing Up for Net Neutrality</a>
	</h2>
	<div class="entry-content">
		<p>Currently there are many political issues that demand
attention however in my opinion there are none that would affect more
people than the possible destruction of net neutrality.</p>

<p><a href="https://en.wikipedia.org/wiki/Net_neutrality">Net neutrality</a> is simply the principle that all data on the internet
should be treated the same. It does not matter if you are visiting Fox
News or Mother Jones - the data and content from both of these
websites (as well as from every other website) should be treated as
equal and that data should be served equally by all Internet Service Providers. Losing net neutrality could
lead to an internet that favors
one of these two sites based on which site is willing to pay more. I
chose these sites because they are such polar opposites but at the same
time we live in a country that allows for such opposites to
have equal protection of freedom of speech. I may disagree with the content of a particular
website but
I do not think it should be served any differently than the website of a
site I do agree with. Destruction of net neutrality will lead to greater
influence wielded by larger corporations and could
stifle smaller websites and startups.</p>

<p>Fortunately, there is still time to act. On July 12, various online
communities and users will come together to stand tall and sound the
alarm about the FCC&rsquo;s attack on net neutrality. Join us
<a href="https://www.battleforthenet.com/july12">here</a>!</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-07-05T21:26:12-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/internet/'>internet</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/03/26/pronto-post-mortem/">
		
			Pronto Post-mortem</a>
	</h2>
	<div class="entry-content">
		<p>Pronto bike share ends this Friday March 31st and I will miss it for
sure. I <a href="http://zachstednick.name/blog/2016/02/09/thoughts-on-pronto/">wrote about why Pronto mattered to me</a> and I
even rode a Pronto bike in the 25
mile <a href="http://www.obliteride.org/">Obliteride</a> last year:</p>

<p><img src="http://zachstednick.com/IMG_2260.JPG"></p>

<p>In October 2015, there was a Pronto sponsored
<a href="https://www.prontocycleshare.com/datachallenge">contest</a> to visualize
bikeshare ride data. I created an
<a href="http://prontostories.com/">entry</a> which although did not win, was a
nice introduction for me to learn mapping with
<a href="d3js.org">D3</a>. As I was
checking out the Pronto site one last time today I noticed that they had
updated their publically available dataset to include 2016
ride data as well as the 2015 ride data.</p>

<p><img src="http://zachstednick.com/pronto_historical_ridership.png"></p>

<p>To me it seems that Pronto had a hard time expanding and encouraging
repeat riders. Unfortunately we do not have the membership data but if
we can assume that people who did not ride much in 2015 did not renew
their membership in 2016 then it looks pretty clear that Pronto was hurting
more than people thought. Also, it looked like they had good success in
2015 with getting people to buy day passes especially during peak tourist
season in the summer and were able to replicate that success in 2016. I
feel there is a need for a dedicated
bike share in Seattle however this iteration of bike share does not
appear to be the solution we need.</p>

<p>I went back to the Pronto site to fetch all my data because of an idea I
worked on then abandoned last summer. The idea was for a website that
was basically <a href="https://www.strava.com/">Strava</a> for Pronto
whereby you compared your ride time data to everyone else&rsquo;s and mapped out how
fast you were compared to them. Pronto did not make it easy to download
all your trip data so I ended up having to write a webscraper to get out
my own data (Hint, hint Pronto 2.0!) which I put at this <a href="https://github.com/stedy/pronto-scraper">GitHub
repository</a>. I never was able
to get my project past the personal level and my ultimate goal was to
simply make a map of the route and add
in plots. Here is an example of all trips from Fairview Ave N &amp; Ward St
to Westlake Ave &amp; 6th Ave:</p>

<iframe src="http://zachstednick.com/strava_for_pronto_demo.html" marginwidth="0" marginheight="0" style="height:700px; width:1260px;" scrolling="no"></iframe>


<p>I&rsquo;m sad that I can&rsquo;t work on this project anymore but maybe with Pronto
2.0 I will be able to revist this idea.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-03-26T17:21:03-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/pronto-biking-seattle-r/'>pronto,biking,seattle,r</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/03/07/have-there-been-more-upsets-in-the-ncaa-tournament-recently/">
		
			Have There Been More Upsets in the NCAA Tournament Recently?</a>
	</h2>
	<div class="entry-content">
		<p>I have been following the <a href="https://en.wikipedia.org/wiki/NCAA_Division_I_Men%27s_Basketball_Tournament">NCAA Men&rsquo;s Basketball
Tournament</a>
for as long
as I can remember and with Selection Sunday coming up, I wondered if
there
have been more or less upsets in recent tournaments. To look at this
visually I used a hypothetical perfect bracket as a reference (i.e. #1
seed beats #16 seed, #2 seed beats #15 seed all the way to #1 seed beating a #2 seed). I
took the sum of all the winning seed numbers at each round in the
Regional Tournament and used that as the denominator
for comparison with the other Regional Tournaments for that particular
year.</p>

<p>I went back in time as far as I could but the <a href="https://en.wikipedia.org/wiki/2007_NCAA_Division_I_Men's_Basketball_Tournament">2007
Tournament</a>
finally harmonized the names of the Regional tournaments with the names
East, West, South, and
Midwest which made for easier comparison across years.</p>

<p><img src="http://zachstednick.com/NCAA_by_region.png"></p>

<p>Clearly there have been quite a lot of upsets in the past ten years
especially within the Midwest Region.</p>

<p>I then went back and looked at all games back to 1985 when
the Tournament first expanded to 64 teams. For this I did not have all
the Regional Tournament information so I just looked at all the games
(except the Final Four).</p>

<p><img src="http://zachstednick.com/NCAA_all_by_year.png"></p>

<p>The aggregate data is pretty volatile year over year as well with a low
in
<a href="https://en.wikipedia.org/wiki/2007_NCAA_Division_I_Men's_Basketball_Tournament">2007</a>. If anything, this shows we should be in for another great year of NCAA tournament basketball complete with some (hopefully many) exciting upsets.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-03-07T13:19:58-08:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/r-basketball/'>r,basketball</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/03/02/a-forgotten-cron-job-leads-to-interesting-results/">
		
			A Forgotten Cron Job Leads to Interesting Results</a>
	</h2>
	<div class="entry-content">
		<p>On January 1, 2016 I set up a <a href="https://en.wikipedia.org/wiki/Cron">cron</a> job to perform a daily count of the number of Twitter followers of the two main Gubernatorial candidates in Washington State: <a href="https://twitter.com/GovInslee">Jay Inslee</a> and <a href="https://twitter.com/BillBryantWA">Bill Bryant</a>. I was not attempting to predict the election or do anything with the data, I just wanted to count followers until Election Day 2016 and hopefully plot some interesting results. I checked on Election Day and the trend lines remained pretty much the same as they did at the start of the year so I abandonded my idea. Today I was cleaning out my crontab file and I found that the cron job was still running. I added a solid line for the 2016 Election Day and dashed line for the 2017 Presidential Inauguration.</p>

<p><img src="http://zachstednick.com/Inslee_vs_Bryant.png"></p>

<p>To me, the follower count data after the inauguration is the most interesting but it is just count data and I am not sure how much you can really read into it. If anything, forgetting the cron job was a pleasant surprise that reminded me of this guy who took a screenshot of the New York Times frontpage everyday for 5 years <a href="https://www.youtube.com/watch?v=sCKGOiauJCE">YouTube</a>.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-03-02T15:15:33-08:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/r-twitter/'>r,twitter</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/01/01/first-book-of-the-year/">
		
			First Book of the Year</a>
	</h2>
	<div class="entry-content">
		<p>Last year I started off the year by making Ashlee Vance&rsquo;s
<a href="https://www.librarything.com/work/15743242/book/124695914">biography</a>
of Elon Musk the first book I read all year.
I wanted to start 2016 off better than 2015 and thought this book might
help my thinking. The story is on Musk is quite interesting if anything
to simply show how much he believes in himself even when the odds seem
stacked against him and the money in the bank grows lower. I tried to
use Musk&rsquo;s story to improve my own self-confidence and I felt like the most concrete way I
was able to do so was to reduce the amount I took on and instead focus
on doing a better job of what I had in front of me.</p>

<p>I will be repeating this little project in 2017 by starting the year off
by reading <a href="https://www.librarything.com/work/8586497">Spread Spectrum:Hedy Lamarr and
the mobile phone</a> by Rob
Walters. I know very little about <a href="https://en.wikipedia.org/wiki/Spread_spectrum">spread spectrum
technology</a> and <a href="https://en.wikipedia.org/wiki/Hedy_Lamarr">Hedy
Lamarr</a> had a very
interesting life and is greatly underappreciated in
modern society. Hopefully this book will prove to be as motivational
over the course of the year in a similar manner as Musk&rsquo;s biography was.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-01-01T15:10:38-08:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/books/'>books</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2016/12/08/election-2016/">
		
			Election 2016</a>
	</h2>
	<div class="entry-content">
		<p>It has now been a month since the 2016 US Presidential election and I am
still stunned by the outcome but am ready to move on.</p>

<p>The major issues I focused on while voting at the Presidential level
were a better climate policy
and more equal treatment for minorities and other marginalized
populations. When I stop and think about why these were the major issues
for me, I realize that I am pretty fortunate. I have a great job,
generally feel safe, and am optimistic overall about the future and the
economy.</p>

<p>The biggest realization for me was that although I care deeply about
these issues on a national level, I need to be more involved at the
community level.</p>

<p>After thinking about it, there are three ways I want to get more
politically involved:</p>

<ol>
<li><p>Increase the amount of money I donate to specific organizations on a
recurring basis.</p></li>
<li><p>Get more involved with organizations that focus on climate advocacy
and immigrant populations. I did do some volunteer work with
<a href="https://carbonwa.org">CarbonWA</a> and I want to get more involved with
them as well as with an organization that focuses on immigrants such as
<a href="http://www.rewa.org/">ReWA</a></p></li>
<li><p>Write more letters to elected officials about the issues I am most
passionate about. I have helped make a github
<a href="https://github.com/openseattle/seattle-boundaries">repo</a> of all the
boundaries of my hometown and I have never used this for any reason
other than looking up addresses. At least I know where to look to figure
out the various districts I live in.</p></li>
</ol>


<p>Will these actions by me make a difference on the national level? Not
likely but hard to say. What they will do for sure is to make an impact
at the local level and will help me to improve the community around me.
If these issues are important
enough for me to write this post about, then it goes to show that they
are important enough for me to get more involved with.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2016-12-08T14:30:57-08:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/political/'>political</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2016/09/02/has-the-pac-12-network-decreased-uw-home-football-game-attendance/">
		
			Has the Pac-12 Network Decreased UW Home Football Game Attendance?</a>
	</h2>
	<div class="entry-content">
		<p>The University of Washington Husky football team is taking on Rutgers
this Saturday with kickoff at 11 AM PST. This is awfully early to start a game, especially a game that occurs during Labor Day weekend. The game is being aired on the <a href="https://en.wikipedia.org/wiki/Pac-12_Network">Pac-12 Network</a> which is about to enter its fifth year of operation. This made me wonder, with the presence of the Pac-12 Network, has attendance decreased at home UW football games?</p>

<p>Fortunately, Wikipedia lists game attendance which allows for a quick
overview of UW home games stratified by network:</p>

<p><img src="http://zachstednick.com/UW_football_attendance_by_TV.png"></p>

<p>The purple dots are UW home games shown on the Pac-12 network, not
entirely convincing but at first glance they don&rsquo;t look too great for
the network. I then looked at only home Pac-10/Pac-12 games and looked at attendance
by season:</p>

<p><img src="http://zachstednick.com/UW_football_total_attendance.png"></p>

<p>That high point in this figure is UW versus Oregon in 2013 while that particularly low point in 2015 was versus Arizona on Halloween
which happened to fall on a Thursday in 2015. Why some executive at FS1 thought it would be a good idea to schedule a game then is beyond me.</p>

<p>In 2012, UW played its home games at <a href="https://en.wikipedia.org/wiki/CenturyLink_Field">CenturyLink
Field</a>, while <a href="https://en.wikipedia.org/wiki/Husky_Stadium">Husky
Stadium</a> was renovated. For the 2013 season the UW football team returned to play at a smaller Husky
Stadium, did either of these factors impact attendance?</p>

<p><img src="http://zachstednick.com/UW_football_percentage_capacity.png"></p>

<p>Not really, there is a minimal difference in stadium size which is
reflected in this identical-looking figure.</p>

<p>What Pac-12 opponents were the biggest draws on average?</p>

<table>
<thead>
<tr>
<th> Opponent </th>
<th style="text-align:right;"> Average Attendance </th>
</tr>
</thead>
<tbody>
<tr>
<td>          Oregon </td>
<td style="text-align:right;"> 69584</td>
</tr>
<tr>
<td>Washington State </td>
<td style="text-align:right;"> 68862</td>
</tr>
<tr>
<td>        Colorado </td>
<td style="text-align:right;"> 64373</td>
</tr>
<tr>
<td>             USC </td>
<td style="text-align:right;"> 64046</td>
</tr>
<tr>
<td>    Oregon State </td>
<td style="text-align:right;"> 63777</td>
</tr>
<tr>
<td>        Stanford </td>
<td style="text-align:right;"> 63360</td>
</tr>
<tr>
<td>            UCLA </td>
<td style="text-align:right;"> 62544</td>
</tr>
<tr>
<td>      California </td>
<td style="text-align:right;"> 62541</td>
</tr>
<tr>
<td>         Arizona </td>
<td style="text-align:right;"> 60756</td>
</tr>
</tbody>
</table>


<p>Obviously there are a lot of factors that can&rsquo;t be captured by game
attendance alone but with a significant budget deficit largely blamed on
<a href="http://www.seattletimes.com/sports/uw-huskies/uw-athletic-department-projects-budget-deficit-of-14-million-for-2016-fiscal-year/">reduced
attendance</a>, it seems like it might be time for the UW to analyze if the Pac-12 Network has really been worth the investments to date.</p>

<p>Full code for scraping Wikipedia on
<a href="https://github.com/stedy/blog-supplemental">GitHub</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2016-09-02T12:52:46-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/r-football/'>r,football</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2016/08/16/this-american-life-stats/">
		
			This American Life Stats</a>
	</h2>
	<div class="entry-content">
		<p>Lately I have been listening to episodes of <a href="http://www.thisamericanlife.org/">This American
Life</a> faster than they are making them
which means I have been going back to the archive for past unheard shows. Their website has a nice <a href="http://www.thisamericanlife.org/user/login">user section</a> where you can log in and mark episodes you have heard and your favorites. The archives are arranged by year which naturally got me thinking about the number episodes I have listened to by year. A search of GitHub revealed many libraries for downloading episodes of the podcast but none that were interested in user statistics so I decided to write my own library. I am still very much beginner level with technologies such as passing cookies and CSRF requests which is why I ultimately ended up using <a href="https://splinter.readthedocs.io/en/latest/">Splinter</a> which just lets you automate browser actions. I used that to login and navigate the TAL archives by year. I then used <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> to parse the HTML. Finally, I just wanted to visualize the results so I used Mike Bostock&rsquo;s <a href="https://bl.ocks.org/mbostock/3885304">D3 Bar Chart example</a>.</p>

<iframe src="http://zachstednick.com/TAL_stats.html" marginwidth="0" marginheight="0" style="height:500px; width:1060px;" scrolling="no"></iframe>


<p>Pretty basic but it gets the job done, full code here on
<a href="https://github.com/stedy/TAL_stats">GitHub</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2016-08-16T22:19:24-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/d3-python/'>d3,python</a>


</div>
	
</div>
</article>

<nav id="pagenavi">
    
    
        <a href="/posts/2" class="next">Next</a>
    
    <div class="center"><a href="/blog/archives">Blog Archives</a></div>
</nav>
</div>
	<footer id="footer" class="inner">Copyright &copy; 2017

    Zach Stednick

</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->






</body>
</html>