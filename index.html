
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>Zach Stednick</title>
	<meta name="author" content="Zach Stednick">

	
	<meta name="description" content="One of the things people consistently tell me when they are
considering buying or renting a house/apartment in a new location is
that they want to &hellip;">
	
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="Zach Stednick" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script async="true" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">Zach Stednick</a></h1>
<nav id="main-nav"><ul class="main">
	<li><a href="/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul class="main">
	<li><a href="/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="https://www.google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:stedy.github.io">
			</form>
		</div>
	</div>
</nav>
<nav id="sub-nav" class="alignright">
	<div class="social">
		
		
		
		<a class="twitter" href="http://twitter.com/zachstednick" title="Twitter">Twitter</a>
		
		
		<a class="github" href="https://github.com/stedy" title="GitHub">GitHub</a>
		
    
		
		
		
		
		
		<a class="rss" href="/atom.xml" title="RSS">RSS</a>
		
    
	</div>
	<form class="search" action="https://www.google.com/search" method="get">
		<input class="alignright" type="text" name="q" results="0">
		<input type="hidden" name="q" value="site:stedy.github.io">
	</form>
</nav>

</header>
	
		
	
	<div id="content" class="inner">


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2018/05/27/a-visual-ranking-of-seattle-public-elementary-schools/">
		
			A Visual Ranking of Seattle Public Elementary Schools</a>
	</h2>
	<div class="entry-content">
		<p>One of the things people consistently tell me when they are
considering buying or renting a house/apartment in a new location is
that they want to move somewhere with &ldquo;good schools&rdquo;. This always maks
me think what is a &ldquo;good
school&rdquo; and more importantly, how do we quanitfy what schools are
considered &ldquo;good&rdquo;? Generally this
means using some sort of list of school data summarized in a fact sheet
from a realtor/apartment manager or more likely using a
websearch that results in sites such as
<a href="https://www.niche.com/k12/thurgood-marshall-elementary-school-seattle-wa/">Niche</a>.
This approach is generally fine but it assumes that you are only
interested in a specific neighborhood which may be difficult to achieve
right now in most major cities across the US and especially in
<a href="https://www.seattletimes.com/business/real-estate/new-home-price-records-777000-in-seattle-950000-on-the-eastside/">Seattle</a>.</p>

<p>What if instead we looked at school ratings in all neighborhoods
simultaneously in a city? This would
allow the user to spot trends and make some visual comparisons as well
as possibly identify overperforming schools in unexpected areas.
Fortunately, Seattle Public Schools (SPS) provides quite a lot of
<a href="https://www.seattleschools.org/cms/One.aspx?portalId=627&amp;pageId=6369011">data</a>
about their schools which makes this easy to visualize.</p>

<h1>Setup</h1>

<ul>
<li><p>For this analysis I just used the SPS data for the 2016-17 school
year.</p></li>
<li><p>I focused solely on elementary school data for the 2016-17
school year. I used the SPS district boundary map for all elementary
schools in the City of Seattle and ignored any magnet or alternative
elementary schools.</p></li>
</ul>


<h1>Rankings</h1>

<p>My initial questions were focused on what school has the best
student/teacher ratio? What
school has the best attendance and what schools are good for reading and
math?</p>

<p>I took the student/teacher ratio, attendance rate, and reading and math
proficiency scores for each school and calculated the rank of that
school
within the city and made this table. Click on the category name to sort
by that category.</p>

<p><link rel="stylesheet" type="text/css"
src="http://cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css" /></p>

<script src="https://code.jquery.com/jquery-3.3.1.min.js"
        integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
        crossorigin="anonymous">
</script>




<script type="text/javascript"
src="http://cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"
></script>


<script>
$(document).ready( function () {
      $('#myTable').DataTable({paging: false, info: false});
} );

</script>








<table border=1 id="myTable">
  <thead>
<tr> <th> School Name </th> <th> Attendance Rank </th> <th>
Student/Teacher Ratio Rank </th> <th> Grade 3 Math Rank </th> <th> Grade
3 Reading Rank </th>  </tr>
</thead>
<tbody>
  <tr> <td> Adams </td> <td align="right"> 12 </td> <td align="right">
53 </td> <td align="right"> 29 </td> <td align="right"> 21 </td> </tr>
  <tr> <td> Alki </td> <td align="right"> 20 </td> <td align="right"> 35
</td> <td align="right"> 12 </td> <td align="right"> 15 </td> </tr>
  <tr> <td> Arbor Heights </td> <td align="right"> 21 </td> <td
align="right"> 31 </td> <td align="right"> 45 </td> <td align="right">
33 </td> </tr>
  <tr> <td> Gatzert </td> <td align="right"> 42 </td> <td align="right">
4 </td> <td align="right"> 49 </td> <td align="right"> 56 </td> </tr>
  <tr> <td> Beacon Hill Int&#8217;l </td> <td align="right"> 1 </td> <td
align="right"> 32.50 </td> <td align="right"> 30 </td> <td
align="right"> 37 </td> </tr>
  <tr> <td> B.F. Day </td> <td align="right"> 16 </td> <td
align="right"> 43 </td> <td align="right"> 25 </td> <td align="right">
23 </td> </tr>
  <tr> <td>  Broadview-Thomson K-8 </td> <td align="right"> 49 </td> <td
align="right"> 2 </td> <td align="right"> 46 </td> <td align="right"> 45
</td> </tr>
  <tr> <td> Bryant </td> <td align="right"> 6 </td> <td align="right">
55 </td> <td align="right"> 3 </td> <td align="right"> 4 </td> </tr>
  <tr> <td> Cascadia </td> <td align="right"> 2 </td> <td align="right">
59 </td> <td align="right"> 1 </td> <td align="right"> 1 </td> </tr>
  <tr>  <td> Catharine Blaine K-8 </td> <td align="right"> 38 </td> <td
align="right"> 15 </td> <td align="right"> 6 </td> <td align="right"> 13
</td> </tr>
  <tr>  <td> Concord Int&#8217;l </td> <td align="right"> 44 </td> <td
align="right"> 22 </td> <td align="right"> 59 </td> <td align="right">
60 </td> </tr>
  <tr>  <td> Bagley </td> <td align="right"> 10 </td> <td align="right">
20 </td> <td align="right"> 24 </td> <td align="right"> 19 </td> </tr>
  <tr>  <td> Dearborn Park Int&#8217;l </td> <td align="right"> 61 </td> <td
align="right"> 61 </td> <td align="right"> 61 </td> <td align="right">
61 </td> </tr>
  <tr>  <td> Dunlap </td> <td align="right"> 43 </td> <td align="right">
5 </td> <td align="right"> 56 </td> <td align="right"> 55 </td> </tr>
  <tr>  <td> Emerson </td> <td align="right"> 58 </td> <td
align="right"> 14 </td> <td align="right"> 43 </td> <td align="right">
53 </td> </tr>
  <tr>  <td> Fairmount Park </td> <td align="right"> 22 </td> <td
align="right"> 47 </td> <td align="right"> 2 </td> <td align="right"> 3
</td> </tr>
  <tr>  <td> Coe </td> <td align="right"> 9 </td> <td align="right"> 48
</td> <td align="right"> 10 </td> <td align="right"> 9 </td> </tr>
  <tr>  <td> Gatewood </td> <td align="right"> 35 </td> <td
align="right"> 26 </td> <td align="right"> 33 </td> <td align="right">
40 </td> </tr>
  <tr>  <td> Genesee Hill </td> <td align="right"> 24 </td> <td
align="right"> 50 </td> <td align="right"> 16 </td> <td align="right">
20 </td> </tr>
  <tr>  <td> Graham Hill </td> <td align="right"> 39 </td> <td
align="right"> 10 </td> <td align="right"> 55 </td> <td align="right">
49 </td> </tr>
  <tr>  <td> Green Lake </td> <td align="right"> 31 </td> <td
align="right"> 37 </td> <td align="right"> 26 </td> <td align="right">
28 </td> </tr>
  <tr>  <td> Greenwood </td> <td align="right"> 15 </td> <td
align="right"> 54 </td> <td align="right"> 20 </td> <td align="right">
17 </td> </tr>
  <tr>  <td> Hawthorne </td> <td align="right"> 46 </td> <td
align="right"> 16 </td> <td align="right"> 48 </td> <td align="right">
41 </td> </tr>
  <tr>  <td> Highland Park </td> <td align="right"> 48 </td> <td
align="right"> 6 </td> <td align="right"> 57 </td> <td align="right"> 50
</td> </tr>
  <tr>  <td> Hay </td> <td align="right"> 8 </td> <td align="right"> 38
</td> <td align="right"> 19 </td> <td align="right"> 10 </td> </tr>
  <tr>  <td> John Muir </td> <td align="right"> 23 </td> <td
align="right"> 25 </td> <td align="right"> 52 </td> <td align="right">
48 </td> </tr>
  <tr>  <td> John Rogers </td> <td align="right"> 33 </td> <td
align="right"> 24 </td> <td align="right"> 34 </td> <td align="right">
34 </td> </tr>
  <tr>  <td> Kimball </td> <td align="right"> 30 </td> <td
align="right"> 32.50 </td> <td align="right"> 40 </td> <td
align="right"> 36 </td> </tr>
  <tr>  <td> Lafayette </td> <td align="right"> 29 </td> <td
align="right"> 44 </td> <td align="right"> 27 </td> <td align="right">
25 </td> </tr>
  <tr>  <td> Laurelhurst </td> <td align="right"> 34 </td> <td
align="right"> 49 </td> <td align="right"> 15 </td> <td align="right">
24 </td> </tr>
  <tr>  <td> Lawton </td> <td align="right"> 26 </td> <td align="right">
42 </td> <td align="right"> 4 </td> <td align="right"> 6 </td> </tr>
  <tr>  <td> Leschi </td> <td align="right"> 53 </td> <td align="right">
36 </td> <td align="right"> 37 </td> <td align="right"> 44 </td> </tr>
  <tr>  <td> Lowell </td> <td align="right"> 60 </td> <td align="right">
3 </td> <td align="right"> 58 </td> <td align="right"> 54 </td> </tr>
  <tr>  <td> Loyal Heights </td> <td align="right"> 17 </td> <td
align="right"> 58 </td> <td align="right"> 5 </td> <td align="right"> 7
</td> </tr>
  <tr>  <td> Madrona </td> <td align="right"> 52 </td> <td
align="right"> 1 </td> <td align="right"> 47 </td> <td align="right"> 43
</td> </tr>
  <tr>  <td> Maple </td> <td align="right"> 19 </td> <td align="right">
28 </td> <td align="right"> 31 </td> <td align="right"> 32 </td> </tr>
  <tr>  <td> MLK Jr. </td> <td align="right"> 45 </td> <td
align="right"> 8 </td> <td align="right"> 54 </td> <td align="right"> 58
</td> </tr>
  <tr>  <td> McDonald International </td> <td align="right"> 7 </td> <td
align="right"> 30 </td> <td align="right"> 23 </td> <td align="right"> 2
</td> </tr>
  <tr>  <td> McGilvra </td> <td align="right"> 25 </td> <td
align="right"> 40 </td> <td align="right"> 14 </td> <td align="right">
11 </td> </tr>
  <tr>  <td> Montlake </td> <td align="right"> 37 </td> <td
align="right"> 51 </td> <td align="right"> 9 </td> <td align="right"> 16
</td> </tr>
  <tr>  <td> North Beach </td> <td align="right"> 14 </td> <td
align="right"> 46 </td> <td align="right"> 13 </td> <td align="right">
12 </td> </tr>
  <tr>  <td> Northgate </td> <td align="right"> 51 </td> <td
align="right"> 11 </td> <td align="right"> 50 </td> <td align="right">
51 </td> </tr>
  <tr>  <td> Olympic Hills </td> <td align="right"> 41 </td> <td
align="right"> 34 </td> <td align="right"> 21 </td> <td align="right">
30 </td> </tr>
  <tr>  <td> Olympic View </td> <td align="right"> 27 </td> <td
align="right"> 56 </td> <td align="right"> 32 </td> <td align="right">
29 </td> </tr>
  <tr>  <td> Queen Anne </td> <td align="right"> 28 </td> <td
align="right"> 57 </td> <td align="right"> 28 </td> <td align="right">
22 </td> </tr>
  <tr>  <td> Rainier View </td> <td align="right"> 55 </td> <td
align="right"> 21 </td> <td align="right"> 18 </td> <td align="right">
26 </td> </tr>
  <tr>  <td> Roxhill </td> <td align="right"> 56 </td> <td
align="right"> 13 </td> <td align="right"> 53 </td> <td align="right">
57 </td> </tr>
  <tr>  <td> Sacajawea </td> <td align="right"> 36 </td> <td
align="right"> 7 </td> <td align="right"> 42 </td> <td align="right"> 42
</td> </tr>
  <tr>  <td> Sand Point </td> <td align="right"> 47 </td> <td
align="right"> 27 </td> <td align="right"> 39 </td> <td align="right">
35 </td> </tr>
  <tr>  <td> Sanislo </td> <td align="right"> 57 </td> <td
align="right"> 12 </td> <td align="right"> 60 </td> <td align="right">
59 </td> </tr>
  <tr>  <td> Stevens </td> <td align="right"> 32 </td> <td
align="right"> 29 </td> <td align="right"> 35 </td> <td align="right">
31 </td> </tr>
  <tr>  <td> Thornton Creek </td> <td align="right"> 18 </td> <td
align="right"> 17 </td> <td align="right"> 41 </td> <td align="right">
38 </td> </tr>
  <tr>  <td> Thurgood Marshall </td> <td align="right"> 5 </td> <td
align="right"> 39 </td> <td align="right"> 8 </td> <td align="right"> 18
</td> </tr>
  <tr>  <td> Van Asselt </td> <td align="right"> 59 </td> <td
align="right"> 9 </td> <td align="right"> 51 </td> <td align="right"> 52
</td> </tr>
  <tr>  <td> Viewlands </td> <td align="right"> 40 </td> <td
align="right"> 19 </td> <td align="right"> 44 </td> <td align="right">
47 </td> </tr>
  <tr>  <td> View Ridge </td> <td align="right"> 3 </td> <td
align="right"> 52 </td> <td align="right"> 11 </td> <td align="right"> 5
</td> </tr>
  <tr>  <td> Wedgwood </td> <td align="right"> 11 </td> <td
align="right"> 41 </td> <td align="right"> 7 </td> <td align="right"> 14
</td> </tr>
  <tr>  <td> West Seattle Elem </td> <td align="right"> 54 </td> <td
align="right"> 23 </td> <td align="right"> 38 </td> <td align="right">
46 </td> </tr>
  <tr>  <td> West Woodland </td> <td align="right"> 13 </td> <td
align="right"> 45 </td> <td align="right"> 17 </td> <td align="right"> 8
</td> </tr>
  <tr>  <td> Whittier </td> <td align="right"> 4 </td> <td
align="right"> 60 </td> <td align="right"> 22 </td> <td align="right">
27 </td> </tr>
  <tr>  <td> Wing Luke </td> <td align="right"> 50 </td> <td
align="right"> 18 </td> <td align="right"> 36 </td> <td align="right">
39 </td> </tr>
  <tr>  <td> Schmitz Park </td> <td align="right"> 62 </td> <td
align="right"> 62 </td> <td align="right"> 62 </td> <td align="right">
62 </td> </tr>
</tbody>
</table>


<p>What jumps out most at me is that no particular school leads all the
other schools consistently and it can make it challenging to decide what
to prioritize when choosing a school.</p>

<h1>Student/Teacher ratio</h1>

<p>Each school reports the number of enrolled students and the number of
teachers which I simply used to calculate a ratio.</p>

<p><em>Click on an attendance area for the exact percentage.</em></p>

<iframe src="http://zachstednick.com/student_teacher_ratio_map.html"
height=850 width=520></iframe>


<h1>Attendance</h1>

<p>I was initially interested in student attendance, but the elementary
school with the
lowest daily attendance was Lowell Elementary with an attendance rate of
89%. Every other school reported an attendance rate at or
above 95% which did not make for a very interesting map. I later learned
that Washington State has a compulsory
attendance <a href="http://apps.leg.wa.gov/RCW/default.aspx?cite=28A.225">law</a>
which likely affected these numbers.</p>

<h1>Reading proficiency</h1>

<p>I was interested in looking at reading achievement scores district-wide
for 3rd
graders as measured by the <a href="http://www.k12.wa.us/Assessment/StateTesting/default.aspx">Washington State proficiency
test</a></p>

<p><em>Click on an attendance area for the exact percentage.</em></p>

<iframe src="http://zachstednick.com/grade3_reading_map.html" height=850
width=520></iframe>


<h1>Math proficiency</h1>

<p>Similarly, I looked at math achievement scores district-wide for 3rd
graders as measured by the <a href="http://www.k12.wa.us/Assessment/StateTesting/default.aspx">Washington State proficiency
test</a></p>

<p><em>Click on an attendance area for the exact percentage.</em></p>

<iframe src="http://zachstednick.com/grade3_math_map.html" height=850
width=520></iframe>


<h1>Family engagement</h1>

<p>SPS provides a parent survey with a variety of questions targeted at
parent enthusiasm. The results of these surveys are not published but
instead we can just look at how many families
complete these surveys.</p>

<p><em>Click on an attendance area for the exact percentage.</em></p>

<iframe src="http://zachstednick.com/family_engagement_map.html"
height=850 width=520></iframe>


<p>The highest school reported that only 49.1% of families responded to the
survey which to me means that most of the families are satisified with
the school but not too excited or disappointed by their school.</p>

<p><strong>tl;dr</strong> Choosing a school is hard but ultimately it comes down to how
satisfied the parents or guardians are with the school. Schools report
on a wide array of metrics about student performance,
but student performance is often an issue of secondary importance when
compared to parents&#8217; overall perception of the quality of a school.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2018-05-27T23:08:01-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/schools/'>schools</a>, <a class='category' href='/blog/categories/seattle/'>seattle,</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2018/05/26/visualizing-flight-data-for-the-2017-seattle-mariners/">
		
			Visualizing Flight Data for the 2017 Seattle Mariners</a>
	</h2>
	<div class="entry-content">
		<p>Remember this map that Facebook created of friend connections back in
2011?</p>

<p><img
src="https://scontent.fsea1-1.fna.fbcdn.net/v/t1.0-9/163413_479288597199_8388607_n.jpg?_nc_cat=0&oh=711d85dd232ab4e2a7b920917eee149a&oe=5B7DD918&efg=eyJhZG1pc3Npb25fY29udHJvbCI6MSwidXBsb2FkZXJfaWQiOiI5NDQ1NTQ3MTk5In0%3D"
height="430" width="670" ></p>

<p>I thought it was pretty cool back then and I still
think its pretty cool. I wanted to make a similar map but was not sure
where to start. I could have done a similar visualization however I
recently quit
Facebook so I can no longer export all my friend&rsquo;s data to use for
making maps. My next thought was visualizing travel routes such as flight information. I am trying to
reduce my carbon footprint which meant I only flew five times in 2017
and have flown exactly zero times so far in 2018. Then I thought, you
know who does
fly alot? The Seattle Mariners.</p>

<p>First step was to collect all the Mariners game data, fortunately
Baseball Reference has all that data in an easily accessible <a href="https://www.baseball-reference.com/teams/SEA/2017-schedule-scores.shtml">HTML
table</a>.</p>

<p>Next step was to geolocate all the stadiums which can be a bit tedious.
Fortunately GitHub user
<a href="https://github.com/the55">the55</a> created a nice JSON file of all the
stadiums and put it as a
<a href="https://gist.github.com/the55/2155142">gist</a>. I was able to use an R
library called
<a href="https://cran.r-project.org/web/packages/geosphere/">geosphere</a> for
using the <a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine
formula</a> to calculate
the distance between two stadiums.</p>

<p>My initial attempt here:</p>

<p><img src="http://zachstednick.com/mariners_base.svg"></p>

<p>In order to make the image look similar to the Facebook connection map,
I ended up using this <a href="https://flowingdata.com/2011/05/11/how-to-map-connections-with-great-circles/">Flowing Data
post</a>
quite a bit to figure out how to
add the lines and change the background color:</p>

<p><img src="http://zachstednick.com/mariners_black_bg.svg"></p>

<p>Finally because there were so many trips from Seattle to American League
West opponents that I ended up adding a bit of <a href="https://en.wikipedia.org/wiki/Jitter">noise or
jitter</a> to the stadium locations
to make the flight paths not perfectly overlap each other.</p>

<p><img src="http://zachstednick.com/mariners_map_with_noise.svg"></p>

<p>Looking back at this 2017 reminded me the Mariners finished 78-84 in
2017, here&rsquo;s hoping to a better season in 2018!</p>

<p>If interested, I put all the code for this analysis
<a href="https://github.com/stedy/blog-supplemental/blob/master/analysis/mariners_2017_travel_map.R">here</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2018-05-26T17:11:21-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/baseball/'>baseball</a>, <a class='category' href='/blog/categories/r/'>r,</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2018/04/05/further-analysis-of-the-2017-18-wa-state-legislature/">
		
			Further Analysis of the 2017-18 WA State Legislature</a>
	</h2>
	<div class="entry-content">
		<p>This is my second post looking at the data from the 2017-18 Washington
State Legislative Session. the first part of this blog can be
read
<a href="http://zachstednick.name/blog/2018/04/05/visualizing-the-2017-18-wa-state-legislature/">here</a></p>

<p>After some time looking at different bills that did pass, I started to
wonder if a bill
was more likely to pass if it had more sponsors. First I took the 647
bills passed by the Legislation and signed into law by Governor and
looked up how many co-sponsors each bill had:</p>

<p><img src="http://zachstednick.com/all_sponsor_counts.png"></p>

<p>Then I I took every bill that was introduced but did not become
law and counted up the sponsors for these:</p>

<p><img src="http://zachstednick.com/all_sponsor_counts_not_passed.png"></p>

<p>So it appears that the number of sponsors is not particulary predictive
for a bill becoming law. The three bills introduced in the Senate with
the highest number of Sponsors were:</p>

<table>
<thead>
<tr>
<th>Bill </th>
<th> Sponsor count </th>
<th style="text-align:right;"> Summary </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://apps2.leg.wa.gov/billsummary?BillNumber=5598&amp;Year=2017">5598</a> </td>
<td> 40 </td>
<td style="text-align:right;"> Granting relatives, including but not limited to grandparents, the right to seek visitation with a child through the courts.</td>
</tr>
<tr>
<td> <a href="http://apps2.leg.wa.gov/billsummary?BillNumber=6037&amp;Year=2017">6037</a> </td>
<td> 28 </td>
<td style="text-align:right;"> Concerning the uniform parentage act.</td>
</tr>
<tr>
<td> <a href="http://apps2.leg.wa.gov/billsummary?BillNumber=5375&amp;Year=2017">5375</a> </td>
<td> 27 </td>
<td style="text-align:right;"> Renaming the cancer research endowment authority to the Andy Hill cancer research endowment.</td>
</tr>
</tbody>
</table>


<p>And in the House:</p>

<table>
<thead>
<tr>
<th>Bill </th>
<th> Sponsor count </th>
<th style="text-align:right;"> Summary </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://apps2.leg.wa.gov/billsummary?BillNumber=2282&amp;Year=2017">2282</a> </td>
<td> 52 </td>
<td style="text-align:right;"> Protecting an open internet in Washington state.</td>
</tr>
<tr>
<td> <a href="http://apps2.leg.wa.gov/billsummary?BillNumber=1714&amp;Year=2017">1714</a> </td>
<td> 45 </td>
<td style="text-align:right;"> Concerning nursing staffing practices at hospitals.</td>
</tr>
<tr>
<td> <a href="http://apps2.leg.wa.gov/billsummary?BillNumber=1400&amp;Year=2017">1400</a> </td>
<td> 42 </td>
<td style="text-align:right;"> Creating Washington state aviation special license plates.</td>
</tr>
</tbody>
</table>


<p>In November 2017, Manka Dhingra won a special election and the
Washington State Senate
flipped from Republican held to Democrat held. Initially I wanted to
focus on the number of bills passed by a Republican held Senate versus a
Democrat held Senate but there were too many extraneous variables such
as passing a budget and a shorter session in 2018. Instead, I decided to
focus on the number of Yea votes by bill</p>

<p><img src ="http://zachstednick.com/percentage_yea_votes.png"></p>

<p>Many of the bills passed were with almost overwhelming support, which is
refreshing to see that there is quite a bit of bipartisanship in
Washington State in 2018.</p>

<p>As always, analysis code on
<a href="https://github.com/stedy/blog-supplemental">GitHub</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2018-04-05T23:11:26-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/legislature/'>legislature</a>, <a class='category' href='/blog/categories/r/'>r,</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2018/04/05/visualizing-the-2017-18-wa-state-legislature/">
		
			Visualizing the 2017-18 WA State Legislature</a>
	</h2>
	<div class="entry-content">
		<p>In his <a href="https://www.governor.wa.gov/news-media/news-media/speeches/2018-state-state">2018 State of the State
speech</a>,
Washington State Governor Jay Inslee
made a passioned appeal for a carbon tax and proposed one in Washington
State Senate bill
<a href="http://apps2.leg.wa.gov/billsummary?BillNumber=6203&amp;Year=2017">6203</a>.
Because of this, I paid more attention to the
activities of the Washington State Legislature than I ever had before
and I found it fascinating.</p>

<p>First off, lets start with the website for the state Legislature. Here
is a screenshot of the
Washington State Legislature page for SB 6203 which is the bill I was
most interested in:</p>

<p><img src="http://zachstednick.com/WA_6203.png"></p>

<p>The website is very resource dense and well worth time exploring when
the Legislature is in session. Every piece of proposed legislation
shows the same amount of information and allows you to easily find and
contact your legislators about a particular bill if interested. The site
also has livestreams of <a href="http://apps2.leg.wa.gov/billsummary?BillNumber=6203&amp;Year=2017#videoSection">committee
hearings</a>
and displays <a href="https://app.leg.wa.gov/far/Senate/Calendar">vote
counts</a> on bills in almost
real time as the votes are tallied on both the
Senate and the House floor.</p>

<p>Is Washington State unique in this regard? Of course not, here is a
screen shot for an interesting bill in Legislature for the State of
California.</p>

<p><img src="http://zachstednick.com/CA_827.png"></p>

<p>Finally here is a screenshot of a House bill on the United States
Congress website</p>

<p><img src="http://zachstednick.com/HR_5031.png"></p>

<p>Does ease of use of the website increase participation in the civic
process at the state level? That is a difficult question to answer but
personally I am glad I get to use the Washington State one instead of
the California State Legislature webpage.</p>

<p>The 2017-18 Washington State Legislative Session ended on <a href="http://leg.wa.gov/legislature/Documents/2018CutoffCalendar.pdf">March 8,
2018</a>
and
Governor Inslee then had 21 days to sign bills into law or veto them.</p>

<p>The conclusion of the 2017-18 Session made me wonder what happened to
those bills that were introduced and how many of them actually became
law.
In addition to a great website, the Washington State
Legislature also has an excellent set of <a href="http://wslwebservices.leg.wa.gov/">Web
Services</a> that allow for
programmatically
capturing metrics and data about activities in the state
legislation. One way to easily visualize this is with a <a href="https://en.wikipedia.org/wiki/Sankey_diagram">Sankey
Diagram</a> (no relation to
this <a href="https://www.youtube.com/watch?v=6Iec080MWCs">Sankey</a> though).</p>

<iframe src="http://zachstednick.com/WA_leg_sankey.html" marginwidth="0" marginheight="0" style="height:600px; width:1060px;" scrolling="no"></iframe>


<p>Here is a smaller image of the diagram with a larger version
<a href="https://zachstednick.com/WA_leg_sankey.html">here</a></p>

<p>Code to generate this figure available on my <a href="https://github.com/stedy/blog-supplemental/">GitHub repo</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2018-04-05T11:25:23-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/d3/'>d3</a>, <a class='category' href='/blog/categories/legislature/'>legislature,</a>, <a class='category' href='/blog/categories/r/'>r,</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/11/30/has-the-pac-12-network-decreased-uw-home-football-game-attendance-updated/">
		
			Has the Pac-12 Network Decreased UW Home Football Game Attendance UPDATED</a>
	</h2>
	<div class="entry-content">
		<p>Following up on my earlier
<a href="http://zachstednick.name/blog/2016/09/02/has-the-pac-12-network-decreased-uw-home-football-game-attendance/">post</a>,
how much has the Pac-12 Network affected game attendance? I updated my previous data set to include the past two seasons so as to include 2008-2017 data. I relied on home game
attendance as reported by Wikipedia and also used Wikipedia to determine what TV network broadcast each home game. In an ideal world I would be able to make better comparisons using the <a href="http://www.nielsen.com/us/en/solutions/measurement/television.html">Nielsen rating</a>
for each game however my guess is that data does not come as cheap or as
easily as data from Wikipedia. For the purposes of this analysis I am
neglecting various other factors in this anaysis
such as time at kickoff, game day temperature, opponent, ranking of UW,
ranking of opponent, etc&hellip; the list goes on and on. My main intention
was
to simply show home game attendance versus TV network for all games:</p>

<p><img src="http://zachstednick.com/UW_football_attendance_by_TV_2008-17.png"></p>

<p>And attendance for Pac-12 only opponents versus TV network:</p>

<p><img src="http://zachstednick.com/UW_football_attendance_by_TV_2008-17_Pac12_only.png"></p>

<p>Based on the available data it appears that attendance during home games
has
been influenced and possibly decreased by the Pac-12 Network but it is
difficult to say for sure while ignoring so many external factors. With
a significant budget deficit still a major
<a href="https://www.seattletimes.com/seattle-news/education/uw-regents-assail-ex-athletic-director-over-growing-deficit/">issue</a>,
one can only hope that losses from game day ticket sales are made up for
with Pac-12 Network advertising revenue.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-11-30T13:10:16-08:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/football/'>football</a>, <a class='category' href='/blog/categories/r/'>r,</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/10/07/states-with-multiple-football-teams-in-the-ap-top-25/">
		
			States With Multiple Football Teams in the AP Top 25</a>
	</h2>
	<div class="entry-content">
		<p>With <a href="http://www.espn.com/college-football/game?gameId=400935292">WSU beating
Oregon</a> and
<a href="http://www.espn.com/college-football/game?gameId=400935293">UW beating UC
Berkeley</a>,
the State of Washington is poised to have two football teams in the top
ten of NCAA Division I football rankings. Naturally this got me
thinking, how often does this happen and how many states have had this
same achievement?</p>

<p>To answer this I used the weekly results of <a href="https://en.wikipedia.org/wiki/AP_Poll">Associated Press
poll</a> which started in 1936 and
thanks to our good friends at <a href="https://donate.wikimedia.org">Wikipedia</a>,
I was able to get AP Poll results for every week.</p>

<p>I found that 25 states had at least one week where two teams from that
state were in the AP Poll. However, the more I thought about it the more
I realized this was slightly biased because some states might only have
one team (i.e. Wyoming) while other states might have two Division I
teams that are never both great at the same time (i.e. Montana). I
tightened down my restrictions a bit and only looked at the top 10 teams
from each AP Poll.</p>

<p>Surprisingly, of the 25 states with at least two teams in the AP top 25
Poll,
21 of those states had a week with at least two teams from that state in the AP top 10.
I made a summary table with the most recent year each state achieved
this distinction listed:</p>

<table>
<thead>
<tr>
<th>state </th>
<th style="text-align:right;"> year </th>
</tr>
</thead>
<tbody>
<tr>
<td>Louisiana</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1936_NCAA_football_rankings">1936</a></td>
</tr>
<tr>
<td>Maryland</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1955_NCAA_football_rankings">1955</a></td>
</tr>
<tr>
<td>North Carolina</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1957_NCAA_University_Division_football_rankings">1957</a></td>
</tr>
<tr>
<td>New York</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1958_NCAA_University_Division_football_rankings">1958</a></td>
</tr>
<tr>
<td>Illinois</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1963_NCAA_University_Division_football_rankings">1963</a></td>
</tr>
<tr>
<td>Indiana</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1979_NCAA_Division_I-A_football_rankings">1979</a></td>
</tr>
<tr>
<td>Pennsylvania</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1982_NCAA_Division_I-A_football_rankings">1982</a></td>
</tr>
<tr>
<td>Colorado</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1994_NCAA_Division_I-A_football_rankings">1994</a></td>
</tr>
<tr>
<td>Kansas</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1995_NCAA_Division_I-A_football_rankings">1995</a></td>
</tr>
<tr>
<td>Washington</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1997_NCAA_Division_I-A_football_rankings">1997</a></td>
</tr>
<tr>
<td>Ohio</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2009_NCAA_Division_I_FBS_football_rankings">2009</a></td>
</tr>
<tr>
<td>Oregon</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2012_NCAA_Division_I_FBS_football_rankings">2012</a></td>
</tr>
<tr>
<td>Florida</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2013_NCAA_Division_I_FBS_football_rankings">2013</a></td>
</tr>
<tr>
<td>South Carolina</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2013_NCAA_Division_I_FBS_football_rankings">2013</a></td>
</tr>
<tr>
<td>Georgia</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2014_NCAA_Division_I_FBS_football_rankings">2014</a></td>
</tr>
<tr>
<td>Mississippi</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2014_NCAA_Division_I_FBS_football_rankings">2014</a></td>
</tr>
<tr>
<td>California</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2015_NCAA_Division_I_FBS_football_rankings">2015</a></td>
</tr>
<tr>
<td>Alabama</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2016_NCAA_Division_I_FBS_football_rankings">2016</a></td>
</tr>
<tr>
<td>Michigan</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2016_NCAA_Division_I_FBS_football_rankings">2016</a></td>
</tr>
<tr>
<td>Texas</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2016_NCAA_Division_I_FBS_football_rankings">2016</a></td>
</tr>
<tr>
<td>Oklahoma</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2017_NCAA_Division_I_FBS_football_rankings">2017</a></td>
</tr>
</tbody>
</table>


<p>Then, I thought what if there were ever a week when a state had 3 teams
in the AP top 10. Sure enough, four states have achieved this:</p>

<table>
<thead>
<tr>
<th>state </th>
<th style="text-align:right;"> year </th>
</tr>
</thead>
<tbody>
<tr>
<td>California</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1952_NCAA_football_rankings">1952</a></td>
</tr>
<tr>
<td>Indiana</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/1967_NCAA_University_Division_football_rankings">1967</a></td>
</tr>
<tr>
<td>Florida</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2005_NCAA_Division_I-A_football_rankings">2005</a></td>
</tr>
<tr>
<td>Texas</td>
<td style="text-align:right;"><a href="https://en.wikipedia.org/wiki/2015_NCAA_Division_I_FBS_football_rankings">2015</a></td>
</tr>
</tbody>
</table>


<p>As always, all of my code for this is on
<a href="https://github.com/stedy/blog-supplemental/">GitHub</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-10-07T22:24:34-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/football/'>football</a>, <a class='category' href='/blog/categories/r/'>r,</a>, <a class='category' href='/blog/categories/wikipedia/'>wikipedia,</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/09/30/further-exploration-of-imdb-tv-show-rating-data/">
		
			Further Exploration of IMDb TV Show Rating Data</a>
	</h2>
	<div class="entry-content">
		<p>I wanted to revist my previous
<a href="http://zachstednick.name/blog/2017/08/09/smarter-binge-watching-with-linear-regression/">post</a>
continuing to look at using linear
regression for determining the best
episodes of a TV show to watch. I started to think about how to look at
this data for multiple TV shows. Performing a linear regression on show
rating by episode number within a season quickly allows us to determine
the maximum and minimum residual for all the show episodes. I took this
a step further and
calculated which episode of the show it was. For example, here are all
the episodes with residual value for that particular show <a href="http://www.imdb.com/title/tt4635276/">Master of
None</a>:</p>

<table>
<thead>
<tr>
<th>Season</th>
<th style="text-align:center;">Episode</th>
<th style="text-align:center;">Name</th>
<th style="text-align:center;">Residual</th>
<th style="text-align:center;">count</th>
<th style="text-align:right;">appearance</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td style="text-align:center;">1</td>
<td style="text-align:center;">               Plan B</td>
<td style="text-align:center;">-0.28</td>
<td style="text-align:center;">1</td>
<td style="text-align:right;">0.05</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">2</td>
<td style="text-align:center;">              Parents</td>
<td style="text-align:center;">0.21</td>
<td style="text-align:center;">2</td>
<td style="text-align:right;">0.1</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">3</td>
<td style="text-align:center;">           Hot Ticket</td>
<td style="text-align:center;">0.01</td>
<td style="text-align:center;">3</td>
<td style="text-align:right;">0.15</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">4</td>
<td style="text-align:center;">        Indians on TV</td>
<td style="text-align:center;">0.21</td>
<td style="text-align:center;">4</td>
<td style="text-align:right;">0.2</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">5</td>
<td style="text-align:center;">        The Other Man</td>
<td style="text-align:center;">-0.09</td>
<td style="text-align:center;">5</td>
<td style="text-align:right;">0.25</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">6</td>
<td style="text-align:center;">            Nashville</td>
<td style="text-align:center;">0.31</td>
<td style="text-align:center;">6</td>
<td style="text-align:right;">0.3</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">7</td>
<td style="text-align:center;"> Ladies and Gentlemen</td>
<td style="text-align:center;">-0.39</td>
<td style="text-align:center;">7</td>
<td style="text-align:right;">0.35</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">8</td>
<td style="text-align:center;">           Old People</td>
<td style="text-align:center;">-0.09</td>
<td style="text-align:center;">8</td>
<td style="text-align:right;">0.4</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">9</td>
<td style="text-align:center;">             Mornings</td>
<td style="text-align:center;">0.11</td>
<td style="text-align:center;">9</td>
<td style="text-align:right;">0.45</td>
</tr>
<tr>
<td>1</td>
<td style="text-align:center;">10</td>
<td style="text-align:center;">               Finale</td>
<td style="text-align:center;">0.01</td>
<td style="text-align:center;">10</td>
<td style="text-align:right;">0.5</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">1</td>
<td style="text-align:center;">            The Thief</td>
<td style="text-align:center;">0.44</td>
<td style="text-align:center;">11</td>
<td style="text-align:right;">0.55</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">2</td>
<td style="text-align:center;">             Le Nozze</td>
<td style="text-align:center;">-0.36</td>
<td style="text-align:center;">12</td>
<td style="text-align:right;">0.6</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">3</td>
<td style="text-align:center;">             Religion</td>
<td style="text-align:center;">-0.27</td>
<td style="text-align:center;">13</td>
<td style="text-align:right;">0.65</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">4</td>
<td style="text-align:center;">           First Date</td>
<td style="text-align:center;">0.13</td>
<td style="text-align:center;">14</td>
<td style="text-align:right;">0.7</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">5</td>
<td style="text-align:center;">     The Dinner Party</td>
<td style="text-align:center;">0.02</td>
<td style="text-align:center;">15</td>
<td style="text-align:right;">0.75</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">6</td>
<td style="text-align:center;"> New York, I Love You</td>
<td style="text-align:center;">0.42</td>
<td style="text-align:center;">16</td>
<td style="text-align:right;">0.8</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">7</td>
<td style="text-align:center;">              Door #3</td>
<td style="text-align:center;">-0.89</td>
<td style="text-align:center;">17</td>
<td style="text-align:right;">0.85</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">8</td>
<td style="text-align:center;">         Thanksgiving</td>
<td style="text-align:center;">0.31</td>
<td style="text-align:center;">18</td>
<td style="text-align:right;">0.9</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">9</td>
<td style="text-align:center;">         Amarsi Un Po</td>
<td style="text-align:center;">0.30</td>
<td style="text-align:center;">19</td>
<td style="text-align:right;">0.95</td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center;">10</td>
<td style="text-align:center;">          Buona Notte</td>
<td style="text-align:center;">-0.10</td>
<td style="text-align:center;">20</td>
<td style="text-align:right;">1</td>
</tr>
</tbody>
</table>


<p>We can see that the episode with the highest residual is S2E1 &ldquo;The
Thief&rdquo; and the episode with the lowest residual is S2E7 &ldquo;Door #3&rdquo;. For
every TV show I took all the episodes and calculated their order as a percent of
the total number of episodes - for example the pilot episode would be 0.0 and the
series
finale would be 1.0 to generate an index. I then took the
maximum and minimum residual values for each show and plotted them
against that episode. For example here is a plot of just Master of None:</p>

<iframe src="http://zachstednick.com/mon_min_max.html" marginwidth="0" marginheight="0" style="height:500px; width:800px;" scrolling="no"></iframe>


<p>To obtain data on as many shows as I could I used this <a href="http://www.imdb.com/search/title?at=0&amp;num_votes=5000,&amp;sort=user_rating,de">IMDb
list</a>
of shows with over 5000 votes and selected the first 1200 shows as a
dataset. I then reused the <a href="http://www.omdbapi.com/">OMDb API</a> as I did before. I then calculated the same values as I did for Master of None
above and plotted them in a similar manner (use the mouseover for more
information on each point):</p>

<iframe src="http://zachstednick.com/imdb_min_max.html" marginwidth="0" marginheight="0" style="height:500px; width:800px;" scrolling="no"></iframe>


<p>Two things immediately jump out at me:</p>

<ol>
<li><p>The density of points right around the zero line shows that linear
regression is a pretty good metric to use for this type of analysis and
that most people rate the show generally in line with the overall trend
for that particular season.</p></li>
<li><p>There seems to be a tendancy for people to really love or really hate
the series finale of TV shows and this shows up by the sheer number of
points at 1. Possibly this is people expressing their overall view of
the show as a whole or maybe people really were really happy or unhappy
with the series finale.</p></li>
</ol>


<p>I put some of the main code I used in a <a href="https://github.com/stedy/blog-supplemental">GitHub
repository</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-09-30T13:57:18-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/r-python-imdb/'>r,python,imdb</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/08/09/smarter-binge-watching-with-linear-regression/">
		
			Smarter Binge Watching With Linear Regression</a>
	</h2>
	<div class="entry-content">
		<p>I am not much of a binge watcher but I do enjoy quality TV shows which
is why I think <a href="http://graphtv.kevinformatics.com/">GraphTV</a> is so
great. GraphTV plots the IMDb user ratings for every episode
and then performs a
<a href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> of
the episode rating by the episode number to create a trend line which
helps you see if the show gets better or worse over the course of the
season.</p>

<p>This is nice but it can get difficult to use GraphTV for shows like
<a href="http://graphtv.kevinformatics.com/tt0088526">Golden Girls</a> and
downright impossible for shows like <a href="http://graphtv.kevinformatics.com/tt0096697">The
Simpsons</a>.</p>

<p>To solve this I created a GitHub repo
<a href="https://github.com/stedy/binge-trendy">binge-trendy</a>. Because the trend
line is fit to the IMDb user rating data, we are
interested in which episodes do IMDb users think are better than the
regression model predicts which translates to any deviation from the
trend line. Since I am only interested in episodes that are
rated higher than the regression model would have predicted,
I only look at episodes with a positive residual.</p>

<p>For example, Golden Girls season 4</p>

<table>
<thead>
<tr>
<th>   Season</th>
<th style="text-align:center;"> Episode </th>
<th style="text-align:right;">                                Name</th>
</tr>
</thead>
<tbody>
<tr>
<td>       4 </td>
<td style="text-align:center;">     1 </td>
<td style="text-align:right;">               Yes, We Have No Havanas</td>
</tr>
<tr>
<td>       4 </td>
<td style="text-align:center;">     2 </td>
<td style="text-align:right;">The Days and Nights of Sophia Petrillo</td>
</tr>
<tr>
<td>       4 </td>
<td style="text-align:center;">     6 </td>
<td style="text-align:right;">              Sophia&rsquo;s Wedding: Part 1</td>
</tr>
<tr>
<td>       4 </td>
<td style="text-align:center;">     9 </td>
<td style="text-align:right;">                       Scared Straight</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   11  </td>
<td style="text-align:right;">                          The Auction</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   14  </td>
<td style="text-align:right;">                       Love Me Tender</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   15  </td>
<td style="text-align:right;">                      Valentine&rsquo;s Day</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   19  </td>
<td style="text-align:right;">              Till Death Do We Volley</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   20  </td>
<td style="text-align:right;">                         High Anxiety</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   22  </td>
<td style="text-align:right;">                      Sophia&rsquo;s Choice</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   23  </td>
<td style="text-align:right;">                      Rites of Spring</td>
</tr>
<tr>
<td>      4  </td>
<td style="text-align:center;">   24  </td>
<td style="text-align:right;">                     Foreign Exchange</td>
</tr>
</tbody>
</table>


<p>I realize the code is not great,
<a href="https://pypi.python.org/pypi/pylint">pylint</a> currently gives it a 6.05 but if there is
one thing I have learned in software:</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en"
dir="ltr">The only way to write good code is to write tons of shitty
code first. Feeling shame about bad code stops you from getting to good
code</p>&mdash; Hadley Wickham (@hadleywickham) <a
href="https://twitter.com/hadleywickham/status/589068687669243905">April
17, 2015</a></blockquote>


<script async src="//platform.twitter.com/widgets.js"
charset="utf-8"></script>


		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-08-09T21:32:39-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/python-imdb/'>python,imdb</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/07/05/standing-up-for-net-neutrality/">
		
			Standing Up for Net Neutrality</a>
	</h2>
	<div class="entry-content">
		<p>Currently there are many political issues that demand
attention however in my opinion there are none that would affect more
people than the possible destruction of net neutrality.</p>

<p><a href="https://en.wikipedia.org/wiki/Net_neutrality">Net neutrality</a> is simply the principle that all data on the internet
should be treated the same. It does not matter if you are visiting Fox
News or Mother Jones - the data and content from both of these
websites (as well as from every other website) should be treated as
equal and that data should be served equally by all Internet Service Providers. Losing net neutrality could
lead to an internet that favors
one of these two sites based on which site is willing to pay more. I
chose these sites because they are such polar opposites but at the same
time we live in a country that allows for such opposites to
have equal protection of freedom of speech. I may disagree with the content of a particular
website but
I do not think it should be served any differently than the website of a
site I do agree with. Destruction of net neutrality will lead to greater
influence wielded by larger corporations and could
stifle smaller websites and startups.</p>

<p>Fortunately, there is still time to act. On July 12, various online
communities and users will come together to stand tall and sound the
alarm about the FCC&rsquo;s attack on net neutrality. Join us
<a href="https://www.battleforthenet.com/july12">here</a>!</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-07-05T21:26:12-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/internet/'>internet</a>


</div>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/03/26/pronto-post-mortem/">
		
			Pronto Post-mortem</a>
	</h2>
	<div class="entry-content">
		<p>Pronto bike share ends this Friday March 31st and I will miss it for
sure. I <a href="http://zachstednick.name/blog/2016/02/09/thoughts-on-pronto/">wrote about why Pronto mattered to me</a> and I
even rode a Pronto bike in the 25
mile <a href="http://www.obliteride.org/">Obliteride</a> last year:</p>

<p><img src="http://zachstednick.com/IMG_2260.JPG"></p>

<p>In October 2015, there was a Pronto sponsored
<a href="https://www.prontocycleshare.com/datachallenge">contest</a> to visualize
bikeshare ride data. I created an
<a href="http://prontostories.com/">entry</a> which although did not win, was a
nice introduction for me to learn mapping with
<a href="d3js.org">D3</a>. As I was
checking out the Pronto site one last time today I noticed that they had
updated their publically available dataset to include 2016
ride data as well as the 2015 ride data.</p>

<p><img src="http://zachstednick.com/pronto_historical_ridership.png"></p>

<p>To me it seems that Pronto had a hard time expanding and encouraging
repeat riders. Unfortunately we do not have the membership data but if
we can assume that people who did not ride much in 2015 did not renew
their membership in 2016 then it looks pretty clear that Pronto was hurting
more than people thought. Also, it looked like they had good success in
2015 with getting people to buy day passes especially during peak tourist
season in the summer and were able to replicate that success in 2016. I
feel there is a need for a dedicated
bike share in Seattle however this iteration of bike share does not
appear to be the solution we need.</p>

<p>I went back to the Pronto site to fetch all my data because of an idea I
worked on then abandoned last summer. The idea was for a website that
was basically <a href="https://www.strava.com/">Strava</a> for Pronto
whereby you compared your ride time data to everyone else&rsquo;s and mapped out how
fast you were compared to them. Pronto did not make it easy to download
all your trip data so I ended up having to write a webscraper to get out
my own data (Hint, hint Pronto 2.0!) which I put at this <a href="https://github.com/stedy/pronto-scraper">GitHub
repository</a>. I never was able
to get my project past the personal level and my ultimate goal was to
simply make a map of the route and add
in plots. Here is an example of all trips from Fairview Ave N &amp; Ward St
to Westlake Ave &amp; 6th Ave:</p>

<iframe src="http://zachstednick.com/strava_for_pronto_demo.html" marginwidth="0" marginheight="0" style="height:700px; width:1260px;" scrolling="no"></iframe>


<p>I&rsquo;m sad that I can&rsquo;t work on this project anymore but maybe with Pronto
2.0 I will be able to revist this idea.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2017-03-26T17:21:03-07:00" pubdate data-updated="true"></time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/pronto-biking-seattle-r/'>pronto,biking,seattle,r</a>


</div>
	
</div>
</article>

<nav id="pagenavi">
    
    
        <a href="/posts/2" class="next">Next</a>
    
    <div class="center"><a href="/blog/archives">Blog Archives</a></div>
</nav>
</div>
	<footer id="footer" class="inner">Copyright &copy; 2018

    Zach Stednick

</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->






</body>
</html>